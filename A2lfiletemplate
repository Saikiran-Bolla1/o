#!/usr/bin/env python3
"""
Update, extend, and merge A2L files using symbol addresses from an ELF (with DWARF).

Additions in this version
- Follow existing A2L syntax when adding: clone a template block from the file (preserves IF_DATA, LINK_MAP, etc.).
- While updating and adding, also update nested LINK_MAP/MAP entries inside blocks:
  - LINK_MAP "symbol" <addr> ... -> rewrites symbol and the first numeric literal after LINK_MAP to the new address.
  - MAP "symbol" <addr> ...       -> same handling (covers vendor variants that use MAP).
- Prefer CHARACTERISTIC over MEASUREMENT for the same symbol across update/add/merge.
- Uppercase all hex addresses touched.

Requires: pip install pyelftools
"""

import sys
import re
import ast
import os
from typing import List, Dict, Optional, Tuple, Set, Union

from elftools.elf.elffile import ELFFile
from elftools.dwarf.descriptions import describe_form_class
from elftools.dwarf.dwarf_expr import DWARFExprParser

# ----------------------------
# Config / Debug
# ----------------------------
A2L_DEBUG = os.environ.get("A2L_DEBUG", "0") not in ("0", "", "false", "False")
DEFAULT_INCLUDE_CONTAINERS = os.environ.get("A2L_INCLUDE_CONTAINERS", "1") not in ("0", "", "false", "False")

# ----------------------------
# DWARF / Symbol helpers
# ----------------------------

MAX_ARRAY = 32

DW_ATE_ADDRESS        = 0x01
DW_ATE_BOOLEAN        = 0x02
DW_ATE_COMPLEX_FLOAT  = 0x03
DW_ATE_FLOAT          = 0x04
DW_ATE_SIGNED         = 0x05
DW_ATE_SIGNED_CHAR    = 0x06
DW_ATE_UNSIGNED       = 0x07
DW_ATE_UNSIGNED_CHAR  = 0x08

def get_symbols(elffile):
    """Return {name: {'addr': int, 'size': int, 'kind': str}} for variables/functions in symbol tables."""
    out = {}
    for secname in ('.symtab', '.dynsym'):
        sec = elffile.get_section_by_name(secname)
        if not sec or not hasattr(sec, "iter_symbols"):
            continue
        for s in sec.iter_symbols():
            name = s.name
            if not name:
                continue
            addr = int(s['st_value'] or 0)
            size = int(s['st_size'] or 0)
            st_type = s['st_info']['type']
            kind = st_type.lower() if isinstance(st_type, str) else str(st_type).lower()
            out[name] = {'addr': addr, 'size': size, 'kind': kind}
    return out

def resolve_typedefs(die):
    """Follow DW_AT_type chain until a concrete type tag."""
    if die is None:
        return None
    seen = set()
    cur = die
    while cur and cur.offset not in seen:
        seen.add(cur.offset)
        if cur.tag in ('DW_TAG_base_type', 'DW_TAG_pointer_type',
                       'DW_TAG_array_type', 'DW_TAG_structure_type', 'DW_TAG_union_type',
                       'DW_TAG_enumeration_type'):
            return cur
        if 'DW_AT_type' in cur.attributes:
            cur = cur.get_DIE_from_attribute('DW_AT_type')
        else:
            break
    return cur

def base_type_info(base_die):
    """Return (type_name, byte_size, encoding) for base/pointer/enum; else (unknown, size, None)."""
    if base_die is None:
        return ('unknown', None, None)
    if base_die.tag == 'DW_TAG_pointer_type':
        bs = base_die.attributes.get('DW_AT_byte_size')
        return ('pointer', int(bs.value) if bs else None, None)
    if base_die.tag == 'DW_TAG_base_type':
        nm = base_die.attributes.get('DW_AT_name')
        bs = base_die.attributes.get('DW_AT_byte_size')
        enc = base_die.attributes.get('DW_AT_encoding')
        return (nm.value.decode('utf-8', 'ignore') if nm else 'unknown',
                int(bs.value) if bs else None,
                int(enc.value) if enc else None)
    if base_die.tag == 'DW_TAG_enumeration_type':
        bs = base_die.attributes.get('DW_AT_byte_size')
        return ('enum', int(bs.value) if bs else None, DW_ATE_SIGNED)
    bs = base_die.attributes.get('DW_AT_byte_size')
    return ('unknown', int(bs.value) if bs else None, None)

def array_len_first_dim(array_die) -> Optional[int]:
    """Get first dimension length from DW_TAG_array_type."""
    for child in array_die.iter_children():
        if child.tag != 'DW_TAG_subrange_type':
            continue
        cnt = child.attributes.get('DW_AT_count')
        if cnt:
            return int(cnt.value)
        ub = child.attributes.get('DW_AT_upper_bound')
        lb = child.attributes.get('DW_AT_lower_bound')
        if ub and lb:
            return int(ub.value) - int(lb.value) + 1
        if ub:
            return int(ub.value) + 1
    return None

def dwarf_type_to_str(tname, tenc, tsize):
    if tenc == DW_ATE_UNSIGNED and tsize == 4: return "uint32"
    if tenc == DW_ATE_UNSIGNED and tsize == 2: return "ushort"
    if tenc == DW_ATE_UNSIGNED and tsize == 1: return "ubyte"
    if tenc == DW_ATE_SIGNED and tsize == 4: return "int32"
    if tenc == DW_ATE_SIGNED and tsize == 2: return "short"
    if tenc == DW_ATE_SIGNED and tsize == 1: return "byte"
    if tenc == DW_ATE_BOOLEAN: return "bool"
    return tname

def should_emit(name, filter_list, filter_hits):
    """Decide if we should EMIT a row for a given fully-qualified name."""
    if not filter_list:
        return True
    matched = False
    for f in filter_list:
        if name == f or name.startswith(f + ".") or name.startswith(f + "._"):
            matched = True
            if filter_hits is not None and f in filter_hits:
                filter_hits[f] += 1
    return matched

def should_traverse(name, filter_list):
    """Decide if we should TRAVERSE a top-level symbol for potential descendants."""
    if not filter_list:
        return True
    for f in filter_list:
        if name == f or name.startswith(f + ".") or name.startswith(f + "._"):
            return True
        if f.startswith(name + ".") or f.startswith(name + "._"):
            return True
    return False

def _decode_lit(op_name: str) -> Optional[int]:
    """Extract literal value from DW_OP_litN op names."""
    if not op_name.startswith('DW_OP_lit'):
        return None
    try:
        return int(op_name[len('DW_OP_lit'):])
    except Exception:
        return None

def _data_member_offset(member_die) -> int:
    """
    Return the byte offset of a struct/union member.

    Handles:
    - DW_AT_data_member_location class 'constant' or 'implicit_const'
    - DW_AT_data_member_location class 'exprloc' or 'block' (DWARF v2 encodings)
    - Bitfields via DW_AT_data_bit_offset / DW_AT_bit_offset -> add bits//8
    """
    loc_attr = member_die.attributes.get('DW_AT_data_member_location')
    bit_off_attr = member_die.attributes.get('DW_AT_data_bit_offset') or member_die.attributes.get('DW_AT_bit_offset')
    bit_extra = 0
    if bit_off_attr is not None:
        try:
            bit_extra = int(bit_off_attr.value) // 8
        except Exception:
            bit_extra = 0

    if not loc_attr:
        return bit_extra

    cls = describe_form_class(loc_attr.form)
    if cls == 'constant':
        try:
            return int(loc_attr.value) + bit_extra
        except Exception:
            return bit_extra

    if cls in ('exprloc', 'block'):
        try:
            parser = DWARFExprParser(member_die.cu.dwarfinfo.structs)
            ops = parser.parse_expr(loc_attr.value)

            offset = 0
            pending_const: Optional[int] = None

            for op in ops:
                name = op.op_name

                if name == 'DW_OP_plus_uconst':
                    try:
                        offset += int(op.args[0])
                    except Exception:
                        pass
                    continue

                if name in (
                    'DW_OP_constu', 'DW_OP_const1u', 'DW_OP_const2u',
                    'DW_OP_const4u', 'DW_OP_const8u',
                    'DW_OP_consts', 'DW_OP_const1s', 'DW_OP_const2s',
                    'DW_OP_const4s', 'DW_OP_const8s'
                ):
                    try:
                        pending_const = int(op.args[0])
                    except Exception:
                        pending_const = None
                    continue

                lit_val = _decode_lit(name)
                if lit_val is not None:
                    pending_const = lit_val
                    continue

                if name in ('DW_OP_plus', 'DW_OP_add'):
                    if pending_const is not None:
                        offset += pending_const
                        pending_const = None
                    continue

            if offset == 0 and pending_const is not None:
                offset += pending_const

            return int(offset) + bit_extra
        except Exception as e:
            if A2L_DEBUG:
                try:
                    form = str(loc_attr.form)
                except Exception:
                    form = "<unknown>"
                print(f"[A2L_DEBUG] Failed to parse member offset expr (form={form}): {e}")
            return bit_extra

    if A2L_DEBUG:
        try:
            form = str(loc_attr.form)
        except Exception:
            form = "<unknown>"
        print(f"[A2L_DEBUG] Unhandled data_member_location class '{cls}' (form={form}), using bit_extra={bit_extra}")
    return bit_extra

def collect_dwarf_struct_vars(prefix, base_addr, die, rows, symbols_dict, filter_list, filter_hits):
    """Recursively collect members/arrays with full hierarchical names using {prefix}._i_ for arrays."""
    die = resolve_typedefs(die)
    if not die:
        if should_emit(prefix, filter_list, filter_hits):
            row = [prefix, hex(base_addr), "unknown", "", "unknown"]
            rows.append(row)
            symbols_dict[prefix] = {
                "address": hex(base_addr),
                "type": "unknown",
                "byte_size": "",
                "kind": "unknown"
            }
        return

    tag = die.tag

    if tag == 'DW_TAG_array_type':
        elem_die = die.get_DIE_from_attribute('DW_AT_type') if 'DW_AT_type' in die.attributes else None
        elem_die = resolve_typedefs(elem_die)
        etname, esize, etenc = base_type_info(elem_die)
        n = array_len_first_dim(die) or 0
        if should_emit(prefix, filter_list, filter_hits):
            row = [prefix, hex(base_addr), f"array[{n}]", esize if esize else "", "array"]
            rows.append(row)
            symbols_dict[prefix] = {
                "address": hex(base_addr),
                "type": f"array[{n}]",
                "byte_size": esize if esize else "",
                "kind": "array"
            }
        n_print = min(n, MAX_ARRAY)
        for i in range(n_print):
            elem_size = esize if esize else 1
            eaddr = base_addr + i * elem_size
            array_elem_prefix = f"{prefix}._{i}_"
            if elem_die and elem_die.tag in ('DW_TAG_structure_type', 'DW_TAG_array_type', 'DW_TAG_union_type'):
                collect_dwarf_struct_vars(array_elem_prefix, eaddr, elem_die, rows, symbols_dict, filter_list, filter_hits)
            else:
                if should_emit(array_elem_prefix, filter_list, filter_hits):
                    row = [array_elem_prefix, hex(eaddr), dwarf_type_to_str(etname, etenc, esize), esize if esize else "", "array_elem"]
                    rows.append(row)
                    symbols_dict[array_elem_prefix] = {
                        "address": hex(eaddr),
                        "type": dwarf_type_to_str(etname, etenc, esize),
                        "byte_size": esize if esize else "",
                        "kind": "array_elem"
                    }
        return

    if tag == 'DW_TAG_structure_type':
        _, tsize, _ = base_type_info(die)
        if should_emit(prefix, filter_list, filter_hits):
            row = [prefix, hex(base_addr), "struct", tsize if tsize else "", "struct"]
            rows.append(row)
            symbols_dict[prefix] = {
                "address": hex(base_addr),
                "type": "struct",
                "byte_size": tsize if tsize else "",
                "kind": "struct"
            }
        for child in die.iter_children():
            if child.tag != 'DW_TAG_member':
                continue
            mname_attr = child.attributes.get('DW_AT_name')
            mname = mname_attr.value.decode('utf-8', 'ignore') if mname_attr else '<anon>'
            off = _data_member_offset(child)
            mt = child.get_DIE_from_attribute('DW_AT_type') if 'DW_AT_type' in child.attributes else None
            if not mt:
                continue
            collect_dwarf_struct_vars(f"{prefix}.{mname}", base_addr + off, mt, rows, symbols_dict, filter_list, filter_hits)
        return

    if tag == 'DW_TAG_union_type':
        _, tsize, _ = base_type_info(die)
        if should_emit(prefix, filter_list, filter_hits):
            row = [prefix, hex(base_addr), "union", tsize if tsize else "", "union"]
            rows.append(row)
            symbols_dict[prefix] = {
                "address": hex(base_addr),
                "type": "union",
                "byte_size": tsize if tsize else "",
                "kind": "union"
            }
        for child in die.iter_children():
            if child.tag != 'DW_TAG_member':
                continue
            mname_attr = child.attributes.get('DW_AT_name')
            mname = mname_attr.value.decode('utf-8', 'ignore') if mname_attr else '<anon>'
            mt = child.get_DIE_from_attribute('DW_AT_type') if 'DW_AT_type' in child.attributes else None
            if not mt:
                continue
            collect_dwarf_struct_vars(f"{prefix}.{mname}", base_addr, mt, rows, symbols_dict, filter_list, filter_hits)
        return

    # leaf/base types
    tname, tsize, tenc = base_type_info(die)
    if should_emit(prefix, filter_list, filter_hits):
        row = [prefix, hex(base_addr), dwarf_type_to_str(tname, tenc, tsize), tsize if tsize else "", "variable"]
        rows.append(row)
        symbols_dict[prefix] = {
            "address": hex(base_addr),
            "type": dwarf_type_to_str(tname, tenc, tsize),
            "byte_size": tsize if tsize else "",
            "kind": "variable"
        }

def build_symbols_dict(elf_path: str, filter_list: Optional[List[str]]) -> Tuple[Dict[str, Dict[str, str]], Set[str]]:
    """
    Use the collector logic to build a symbols_dict filtered by filter_list.
    Returns (symbols_dict, missing_filters)
    """
    with open(elf_path, 'rb') as f:
        elf = ELFFile(f)
        symbols = get_symbols(elf)

        if not elf.has_dwarf_info():
            raise RuntimeError("No DWARF info found in ELF file.")

        if filter_list and len(filter_list) > 0:
            print("Filters provided:", ", ".join(filter_list))
        else:
            print("No filters provided; processing all symbols.")

        dwarfinfo = elf.get_dwarf_info()
        rows = []
        symbols_dict: Dict[str, Dict[str, str]] = {}
        filter_hits = {f: 0 for f in (filter_list or [])}

        for name, meta in sorted(symbols.items(), key=lambda kv: kv[1]['addr']):
            if filter_list and not should_traverse(name, filter_list):
                continue
            addr = meta['addr']
            found = False
            for cu in dwarfinfo.iter_CUs():
                for die in cu.iter_DIEs():
                    if die.tag != 'DW_TAG_variable':
                        continue
                    n = die.attributes.get('DW_AT_name')
                    if not n:
                        continue
                    vname = n.value.decode('utf-8', 'ignore')
                    if vname == name:
                        tdie = die.get_DIE_from_attribute('DW_AT_type') if 'DW_AT_type' in die.attributes else None
                        if tdie:
                            collect_dwarf_struct_vars(name, addr, tdie, rows, symbols_dict, filter_list, filter_hits)
                        else:
                            if should_emit(name, filter_list, filter_hits):
                                symbols_dict[name] = {
                                    "address": hex(addr),
                                    "type": "unknown",
                                    "byte_size": "",
                                    "kind": "unknown"
                                }
                        found = True
                        break
                if found:
                    break

        unmatched = {f for f, c in filter_hits.items() if c == 0}
        if filter_list:
            if unmatched:
                print("Warning: the following filters matched no symbols:")
                for f in unmatched:
                    print(f" - {f}")
            else:
                print("All filters matched at least one symbol.")

        return symbols_dict, unmatched

# ----------------------------
# Hex helpers (force uppercase)
# ----------------------------

def _parse_hex_to_int(addr_hex) -> Optional[int]:
    if isinstance(addr_hex, int):
        return addr_hex
    if not isinstance(addr_hex, str):
        return None
    s = addr_hex.strip()
    try:
        if s.lower().startswith("0x"):
            return int(s, 16)
        return int(s, 16)
    except Exception:
        return None

def to_upper_hex(addr_hex: str) -> str:
    """
    Normalize any hex string like '0x1a2b' to '0x1A2B'. Accepts int as well.
    Returns input as string if parsing fails.
    """
    n = _parse_hex_to_int(addr_hex)
    if n is None:
        if isinstance(addr_hex, str) and addr_hex.strip().lower().startswith("0x"):
            return "0x" + addr_hex.strip()[2:].upper()
        return str(addr_hex)
    return f"0x{n:X}"

# ----------------------------
# A2L parsing and updating
# ----------------------------

class A2LBlock:
    def __init__(self,
                 kind: str,
                 name: str,
                 symbol: str,
                 begin_idx: int,
                 end_idx: int,
                 addr_line_idx: Optional[int],
                 old_addr_int: Optional[int],
                 old_addr_hex: Optional[str]):
        self.kind = kind  # "MEASUREMENT" or "CHARACTERISTIC"
        self.name = name
        self.symbol = symbol  # SYMBOL_LINK if present, else block name
        self.begin_idx = begin_idx
        self.end_idx = end_idx
        self.addr_line_idx = addr_line_idx
        self.old_addr_int = old_addr_int
        self.old_addr_hex = old_addr_hex

MEAS_BEGIN_RE = re.compile(r'^\s*/begin\s+MEASUREMENT\s+(\S+)')
CHAR_BEGIN_RE = re.compile(r'^\s*/begin\s+CHARACTERISTIC\s+(\S+)')
SYMBOL_LINK_RE = re.compile(r'^\s*SYMBOL_LINK\s+"([^"]+)"')
END_BLOCK_RE_TMPL = "/end {}"

# Capture and normalize hex in place
ECU_ADDRESS_RE = re.compile(r'^(\s*ECU_ADDRESS\s+)(0x[0-9A-Fa-f]+)(.*)$')
VALUE_ADDR_RE  = re.compile(r'^(\s*VALUE\s+)(0x[0-9A-Fa-f]+|\d+)(.*)$')
ADDRESS_RE     = re.compile(r'^(\s*ADDRESS\s+)(0x[0-9A-Fa-f]+)(.*)$')
# Decimal fallback for any of the 3 keywords
DEC_ANY_ADDR_RE = re.compile(r'^(\s*(?:ECU_ADDRESS|VALUE|ADDRESS)\s+)(\d+)(.*)$')

# --- Nested LINK_MAP/MAP helpers ---

LINK_OR_MAP_FIND_RE = re.compile(r'\b(LINK_MAP|MAP)\b')

def _rewrite_link_or_map_line(raw: str, symbol: str, addr_hex_up: str) -> Optional[str]:
    """
    If the line contains LINK_MAP or MAP, rewrite the first quoted symbol after the keyword (if any)
    and the first numeric literal (hex or decimal) after the keyword to addr_hex_up.
    Returns the new line (without newline) or None if no change applied.
    """
    m = LINK_OR_MAP_FIND_RE.search(raw)
    if not m:
        return None

    # Split around the keyword to keep prefix untouched
    key_end = m.end()
    prefix = raw[:key_end]
    tail = raw[key_end:]

    changed = False

    # Replace first quoted string in tail with the symbol
    def _replace_first_quote(s: str) -> Tuple[str, bool]:
        q1 = s.find('"')
        if q1 == -1:
            return s, False
        q2 = s.find('"', q1 + 1)
        if q2 == -1:
            return s, False
        return s[:q1] + f'"{symbol}"' + s[q2 + 1:], True

    tail, did_q = _replace_first_quote(tail)
    changed = changed or did_q

    # Replace first numeric literal (hex or decimal) in tail with the address
    num_re = re.compile(r'(0x[0-9A-Fa-f]+|\b\d+\b)')
    tail2, nsubs = num_re.subn(addr_hex_up, tail, count=1)
    if nsubs > 0:
        changed = True
        tail = tail2

    if not changed:
        return None
    return prefix + tail

def _patch_link_map_in_block(out_lines: List[str], begin_idx: int, end_idx: int, symbol: str, addr_hex_up: str) -> None:
    """
    Rewrite LINK_MAP/MAP entries inside [begin_idx, end_idx] inclusive.
    """
    for li in range(begin_idx, end_idx + 1):
        raw = out_lines[li].rstrip("\n")
        if 'LINK_MAP' not in raw and 'MAP' not in raw:
            continue
        new_raw = _rewrite_link_or_map_line(raw, symbol, addr_hex_up)
        if new_raw is not None:
            out_lines[li] = new_raw + "\n"

def parse_a2l_blocks(lines: List[str]) -> Tuple[List[A2LBlock], List[str]]:
    """
    Parse A2L lines and return list of blocks with their symbol names and positions.
    Captures the address line index and current address for delta computation.
    Recognizes ECU_ADDRESS, VALUE, and ADDRESS within blocks (first found wins).
    """
    blocks: List[A2LBlock] = []
    filters: List[str] = []

    i = 0
    n = len(lines)
    while i < n:
        line = lines[i]

        m_meas = MEAS_BEGIN_RE.match(line)
        m_char = CHAR_BEGIN_RE.match(line)

        if m_meas or m_char:
            kind = "MEASUREMENT" if m_meas else "CHARACTERISTIC"
            name = (m_meas or m_char).group(1)
            begin_idx = i
            symbol_name = name
            addr_line_idx: Optional[int] = None
            old_addr_hex: Optional[str] = None
            old_addr_int: Optional[int] = None

            # find end of block
            j = i + 1
            end_idx = None
            while j < n:
                l2 = lines[j]
                # capture SYMBOL_LINK if present
                m_sym = SYMBOL_LINK_RE.match(l2)
                if m_sym:
                    symbol_name = m_sym.group(1).strip()

                # capture first address line (any of the known keywords)
                if addr_line_idx is None:
                    m = ECU_ADDRESS_RE.match(l2) or VALUE_ADDR_RE.match(l2) or ADDRESS_RE.match(l2) or DEC_ANY_ADDR_RE.match(l2)
                    if m:
                        addr_line_idx = j
                        old_addr_hex = m.group(2)
                        try:
                            if isinstance(old_addr_hex, str) and old_addr_hex.lower().startswith("0x"):
                                old_addr_int = int(old_addr_hex, 16)
                            else:
                                old_addr_int = int(old_addr_hex, 10)
                        except Exception:
                            old_addr_int = None

                if l2.strip().lower() == END_BLOCK_RE_TMPL.format(kind.lower()):
                    end_idx = j
                    break
                j += 1
            if end_idx is None:
                end_idx = n - 1  # Unclosed block - treat until EOF

            blocks.append(A2LBlock(kind=kind, name=name, symbol=symbol_name,
                                   begin_idx=begin_idx, end_idx=end_idx,
                                   addr_line_idx=addr_line_idx,
                                   old_addr_int=old_addr_int,
                                   old_addr_hex=old_addr_hex))

            if symbol_name not in filters:
                filters.append(symbol_name)

            i = end_idx + 1
            continue

        i += 1

    return blocks, filters

def force_uppercase_known_address_keywords(lines: List[str]) -> List[str]:
    """
    Ensure all ECU_ADDRESS, ADDRESS, and VALUE lines have uppercase hex for the address field.
    """
    out: List[str] = []
    for line in lines:
        raw = line.rstrip("\n")
        m = ECU_ADDRESS_RE.match(raw)
        if m:
            out.append(f"{m.group(1)}{to_upper_hex(m.group(2))}{m.group(3)}\n")
            continue
        m = ADDRESS_RE.match(raw)
        if m:
            out.append(f"{m.group(1)}{to_upper_hex(m.group(2))}{m.group(3)}\n")
            continue
        m = VALUE_ADDR_RE.match(raw)
        if m:
            out.append(f"{m.group(1)}{to_upper_hex(m.group(2))}{m.group(3)}\n")
            continue
        out.append(line)
    return out

def update_a2l_lines(lines: List[str], blocks: List[A2LBlock], addr_map: Dict[str, str]) -> Tuple[List[str], List[str]]:
    """
    Update the lines for each block using addr_map.

    Enhancements:
    - Also updates nested LINK_MAP/MAP entries inside the block to use the block's symbol and new address.

    Recurring symbol handling:
    - For symbols that appear in multiple blocks, we compute each block's original delta
      from the first occurrence's old address and apply that delta to the newly resolved base address.

    Returns updated lines and a list of warnings for blocks without matches.
    Also forces uppercase hex formatting for ECU_ADDRESS/ADDRESS/VALUE lines across the file.
    """
    out_lines = list(lines)
    warnings: List[str] = []

    # Group blocks by symbol to compute deltas per symbol
    symbol_groups: Dict[str, List[A2LBlock]] = {}
    for b in blocks:
        symbol_groups.setdefault(b.symbol, []).append(b)

    for symbol, group in symbol_groups.items():
        addr_hex = addr_map.get(symbol)
        if not addr_hex:
            for b in group:
                warnings.append(f"No address found for symbol '{symbol}' (block {b.kind} {b.name}).")
            continue

        base_new_int = _parse_hex_to_int(addr_hex)
        if base_new_int is None:
            for b in group:
                warnings.append(f"Resolved address for symbol '{symbol}' is invalid: {addr_hex}")
            continue

        # Determine reference old address (first block with an address)
        ref_old_int: Optional[int] = None
        for b in group:
            if b.old_addr_int is not None:
                ref_old_int = b.old_addr_int
                break

        multi = len(group) > 1 and ref_old_int is not None

        for b in group:
            if b.addr_line_idx is None:
                warnings.append(f"No address line found to update for symbol '{symbol}' (block {b.kind} {b.name}).")
                # Still patch LINK_MAP/MAP if we can
                _patch_link_map_in_block(out_lines, b.begin_idx, b.end_idx, symbol, to_upper_hex(addr_hex))
                continue

            delta = 0
            if multi and b.old_addr_int is not None and ref_old_int is not None:
                delta = b.old_addr_int - ref_old_int

            new_addr_int = base_new_int + delta
            new_addr_hex = f"0x{new_addr_int:X}"

            old = out_lines[b.addr_line_idx].rstrip("\n")

            # Try all known patterns in order: ECU_ADDRESS, VALUE, ADDRESS, then decimal fallback
            m = ECU_ADDRESS_RE.match(old)
            if m:
                new_line = f"{m.group(1)}{new_addr_hex}{m.group(3)}"
                out_lines[b.addr_line_idx] = new_line + "\n"
            else:
                m = VALUE_ADDR_RE.match(old)
                if m:
                    new_line = f"{m.group(1)}{new_addr_hex}{m.group(3)}"
                    out_lines[b.addr_line_idx] = new_line + "\n"
                else:
                    m = ADDRESS_RE.match(old)
                    if m:
                        new_line = f"{m.group(1)}{new_addr_hex}{m.group(3)}"
                        out_lines[b.addr_line_idx] = new_line + "\n"
                    else:
                        m = DEC_ANY_ADDR_RE.match(old)
                        if m:
                            new_line = f"{m.group(1)}{new_addr_hex}{m.group(3)}"
                            out_lines[b.addr_line_idx] = new_line + "\n"
                        else:
                            warnings.append(f"Could not update address line for symbol '{symbol}' (block {b.kind} {b.name}): '{old}'")

            # Patch nested LINK_MAP/MAP entries to follow the same symbol and address
            _patch_link_map_in_block(out_lines, b.begin_idx, b.end_idx, symbol, to_upper_hex(new_addr_hex))

    # After updates, ensure all known keywords have uppercase hex addresses
    out_lines = force_uppercase_known_address_keywords(out_lines)

    return out_lines, warnings

# ----------------------------
# Preference rule (CHAR over MEAS)
# ----------------------------

def _enforce_prefer_characteristic_inplace(lines: List[str]) -> List[str]:
    """
    Preference rule applied to a single A2L file's text:
    - If the same symbol appears as both MEASUREMENT and CHARACTERISTIC, keep the CHARACTERISTIC block(s)
      and remove the MEASUREMENT block(s) for that symbol.
    Returns possibly modified lines.
    """
    blocks, _ = parse_a2l_blocks(lines)
    char_symbols = {b.symbol for b in blocks if b.kind == "CHARACTERISTIC"}
    to_delete: List[Tuple[int, int]] = []
    for b in blocks:
        if b.kind == "MEASUREMENT" and b.symbol in char_symbols:
            to_delete.append((b.begin_idx, b.end_idx))
    if not to_delete:
        return lines
    for begin, end in sorted(to_delete, key=lambda t: t[0], reverse=True):
        del lines[begin:end + 1]
    return lines

# ----------------------------
# Helpers to create new blocks and placement
# ----------------------------

def _guess_datatype_and_limits(meta: Optional[Dict[str, str]]) -> Tuple[str, str, str, str]:
    """
    Guess A2L data keywords and limit ranges from symbol metadata.
    Returns tuple: (meas_datatype, char_deposit, lower, upper)
    For container nodes (struct/array/union), prefer ULONG width.
    """
    kind = (meta or {}).get("kind", "")
    if kind in ("struct", "array", "union"):
        return "ULONG", "ULong_Value", "0", "4294967295"

    t = (meta or {}).get("type", "") if meta else ""
    t = (t or "").lower()
    meas, dep, lower, upper = "UBYTE", "UByte_Value", "0", "255"

    if t in ("bool",):
        meas, dep, lower, upper = "UBYTE", "UByte_Value", "0", "1"
    elif t in ("ubyte", "uint8", "unsigned char"):
        meas, dep, lower, upper = "UBYTE", "UByte_Value", "0", "255"
    elif t in ("byte", "int8", "signed char"):
        meas, dep, lower, upper = "SBYTE", "SByte_Value", "-128", "127"
    elif t in ("ushort", "uint16", "unsigned short"):
        meas, dep, lower, upper = "UWORD", "UWord_Value", "0", "65535"
    elif t in ("short", "int16", "signed short"):
        meas, dep, lower, upper = "SWORD", "SWord_Value", "-32768", "32767"
    elif t in ("uint32", "unsigned int", "unsigned long"):
        meas, dep, lower, upper = "ULONG", "ULong_Value", "0", "4294967295"
    elif t in ("int32", "signed int", "long", "int"):
        meas, dep, lower, upper = "SLONG", "SLong_Value", "-2147483648", "2147483647"
    elif "float" in t:
        meas, dep, lower, upper = "FLOAT32", "Float_Value", "-3.402823e+38", "3.402823e+38"

    return meas, dep, lower, upper

def _render_new_block_minimal(variablename: str, kind: str, addr_hex: str, meta: Optional[Dict[str, str]]) -> List[str]:
    """
    Minimal block renderer (fallback if no template is available).
    """
    meas_dt, char_dep, _, upper = _guess_datatype_and_limits(meta)
    addr_hex_up = to_upper_hex(addr_hex)
    lines: List[str] = []
    if kind == "MEASUREMENT":
        lines.extend([
            f'/begin MEASUREMENT {variablename} ""\n',
            f'  {meas_dt} NO_COMPU_METHOD 0 0 {upper}\n',
            f'  ECU_ADDRESS {addr_hex_up}\n',
            f'  SYMBOL_LINK "{variablename}" 0\n',
            f'/end MEASUREMENT\n',
        ])
    else:  # CHARACTERISTIC
        lines.extend([
            f'/begin CHARACTERISTIC {variablename} ""\n',
            f'  VALUE {addr_hex_up} {char_dep} 0 NO_COMPU_METHOD 0 {upper}\n',
            f'  SYMBOL_LINK "{variablename}" 0\n',
            f'/end CHARACTERISTIC\n',
        ])
    return lines

def _select_block_templates(lines: List[str]) -> Dict[str, List[str]]:
    """
    Choose a template block for each kind (MEASUREMENT and CHARACTERISTIC) from the provided lines.
    Preference:
      - Blocks containing IF_DATA or LINK_MAP get higher score.
      - Longer blocks preferred if tie.
    Returns dict kind -> list of lines representing the template block.
    """
    blocks, _ = parse_a2l_blocks(lines)
    candidates: Dict[str, List[Tuple[int, int, int]]] = {"MEASUREMENT": [], "CHARACTERISTIC": []}
    for b in blocks:
        block_lines = lines[b.begin_idx:b.end_idx + 1]
        text = "".join(block_lines)
        score = 0
        if "IF_DATA" in text:
            score += 2
        if "LINK_MAP" in text or " MAP " in text:
            score += 1
        score += len(block_lines) // 5
        candidates[b.kind].append((score, b.begin_idx, b.end_idx))
    templates: Dict[str, List[str]] = {}
    for kind in ("MEASUREMENT", "CHARACTERISTIC"):
        if not candidates[kind]:
            continue
        score, begin, end = sorted(candidates[kind], key=lambda t: (-t[0], t[1]))[0]
        templates[kind] = list(lines[begin:end + 1])
    return templates

def _render_from_template(kind: str, variablename: str, addr_hex: str, template_lines: List[str]) -> List[str]:
    """
    Clone a template block and replace:
      - name in /begin KIND <name>
      - SYMBOL_LINK "<name>"
      - The address value on ECU_ADDRESS/ADDRESS/VALUE lines (first match)
      - LINK_MAP/MAP nested entries: symbol and first numeric literal after the keyword
    All other lines (including IF_DATA) are preserved.
    """
    if not template_lines:
        return _render_new_block_minimal(variablename, kind, addr_hex, meta=None)

    cloned = [l for l in template_lines]
    name_re = re.compile(rf'^(\s*/begin\s+{kind}\s+)(\S+)(.*)$')
    # Replace begin line name
    for i, l in enumerate(cloned):
        m = name_re.match(l)
        if m:
            trailing_nl = l.endswith("\n")
            newl = f"{m.group(1)}{variablename}{m.group(3)}"
            cloned[i] = newl + ("\n" if trailing_nl and not newl.endswith("\n") else "")
            break

    # Replace SYMBOL_LINK quoted name
    for i, l in enumerate(cloned):
        m = SYMBOL_LINK_RE.match(l)
        if m:
            qstart = l.find('"')
            qend = l.find('"', qstart + 1)
            if qstart != -1 and qend != -1:
                cloned[i] = f'{l[:qstart]}"{variablename}"{l[qend+1:]}'
            break  # usually only one

    # Replace first address occurrence among known patterns
    addr_hex_up = to_upper_hex(addr_hex)
    replaced = False
    for i, l in enumerate(cloned):
        raw = l.rstrip("\n")
        for pat in (ECU_ADDRESS_RE, VALUE_ADDR_RE, ADDRESS_RE, DEC_ANY_ADDR_RE):
            m = pat.match(raw)
            if m:
                cloned[i] = f"{m.group(1)}{addr_hex_up}{m.group(3)}\n"
                replaced = True
                break
        if replaced:
            break

    # Patch LINK_MAP/MAP lines inside the cloned block
    for i in range(len(cloned)):
        raw = cloned[i].rstrip("\n")
        new_raw = _rewrite_link_or_map_line(raw, variablename, addr_hex_up)
        if new_raw is not None:
            cloned[i] = new_raw + "\n"

    # Ensure normalized hex formatting inside the block
    cloned = force_uppercase_known_address_keywords(cloned)
    return cloned

def _normalize_variablename_input(variablename: Union[str, List[str]]) -> List[str]:
    """
    Normalize names:
      - list/tuple/set
      - comma-separated
      - JSON-like list string
      - single string
    Returns a deduplicated list.
    """
    names: List[str] = []
    if isinstance(variablename, (list, tuple, set)):
        names = [str(x).strip() for x in variablename if str(x).strip()]
    elif isinstance(variablename, str):
        s = variablename.strip()
        if s.startswith("[") and s.endswith("]"):
            try:
                parsed = ast.literal_eval(s)
                if isinstance(parsed, (list, tuple, set)):
                    names = [str(x).strip() for x in parsed if str(x).strip()]
                else:
                    names = [s]
            except Exception:
                names = [p.strip() for p in s.strip("[]").split(",") if p.strip()]
        elif "," in s:
            names = [p.strip() for p in s.split(",") if p.strip()]
        elif s:
            names = [s]
    # Deduplicate preserving order
    seen = set()
    uniq = []
    for n in names:
        if n not in seen:
            seen.add(n)
            uniq.append(n)
    return uniq

def _find_insert_position_after_kind(lines: List[str], blocks: List[A2LBlock], kind: str) -> int:
    """
    Returns the line index to insert new blocks right after the last existing block of 'kind'.
    If none exist, returns len(lines) to append at the end.
    """
    last_end = -1
    for b in blocks:
        if b.kind == kind and b.end_idx > last_end:
            last_end = b.end_idx
    if last_end >= 0:
        return last_end + 1
    return len(lines)

# ----------------------------
# Public APIs
# ----------------------------

def Updatea2l(olda2l: str, elf: str, newa2l: str) -> None:
    """
    Update addresses for MEASUREMENT/CHARACTERISTIC (and nested LINK_MAP/MAP), enforce preference,
    and write to newa2l.
    """
    with open(olda2l, "r", encoding="utf-8", errors="ignore") as f:
        lines = f.readlines()

    # Preference enforcement within the file
    lines = _enforce_prefer_characteristic_inplace(lines)

    blocks, filters = parse_a2l_blocks(lines)
    if not blocks:
        print("No MEASUREMENT or CHARACTERISTIC blocks found in A2L.")
    else:
        print(f"Found {len(blocks)} blocks to process.")
    if filters:
        print("Symbols to resolve from ELF:")
        for s in filters:
            print(f" - {s}")

    symbols_dict, missing_filters = build_symbols_dict(elf, filters)
    addr_map = {name: to_upper_hex(meta["address"]) for name, meta in symbols_dict.items()}
    print(f"Resolved {len(addr_map)} symbol addresses from ELF/DWARF.")

    updated_lines, warnings = update_a2l_lines(lines, blocks, addr_map)

    for w in warnings:
        print("Warning:", w)
    if missing_filters:
        print("These A2L symbols were not found in ELF/DWARF:")
        for s in sorted(missing_filters):
            print(f" - {s}")

    updated_lines = _enforce_prefer_characteristic_inplace(updated_lines)
    updated_lines = force_uppercase_known_address_keywords(updated_lines)

    with open(newa2l, "w", encoding="utf-8", errors="ignore") as f:
        f.writelines(updated_lines)
    print(f"Saved updated A2L to: {newa2l}")

def addvariable(olda2l: str, elf: str, variablename: Union[str, List[str]], vartype: str, outputfile: str, include_containers: Optional[bool] = None) -> None:
    """
    Add new variables (ALL filtered, missing from A2L) and update all existing addresses.
    Also patch LINK_MAP/MAP for new and existing blocks.
    """
    kind = (vartype or "").strip().upper()
    if kind not in ("CHARACTERISTIC", "MEASUREMENT"):
        raise ValueError("vartype must be 'characteristic' or 'measurement'")

    if include_containers is None:
        include_containers = DEFAULT_INCLUDE_CONTAINERS

    with open(olda2l, "r", encoding="utf-8", errors="ignore") as f:
        lines = f.readlines()

    lines = _enforce_prefer_characteristic_inplace(lines)

    blocks, filters = parse_a2l_blocks(lines)
    existing_symbols = {b.symbol for b in blocks}
    existing_pairs = {(b.kind, b.symbol) for b in blocks}

    extra_filters = _normalize_variablename_input(variablename)
    for tok in extra_filters:
        if tok not in filters:
            filters.append(tok)

    print(f"Starting 'addvariable' with {len(filters)} filter token(s).")
    if extra_filters:
        print("- Added filter token(s):", ", ".join(extra_filters))
    print(f"- include_containers = {include_containers}")

    symbols_dict, missing_filters = build_symbols_dict(elf, filters)
    addr_map = {name: to_upper_hex(meta["address"]) for name, meta in symbols_dict.items()}
    print(f"Resolved {len(addr_map)} addresses from ELF.")

    # Update addresses for existing blocks (recurring symbol handling + LINK_MAP/MAP patching)
    updated_lines, warnings = update_a2l_lines(lines, blocks, addr_map)
    for w in warnings:
        print("Warning:", w)

    # Refresh parse after update pass
    blocks, _ = parse_a2l_blocks(updated_lines)
    existing_symbols = {b.symbol for b in blocks}
    existing_pairs = {(b.kind, b.symbol) for b in blocks}

    # Determine add candidates
    if include_containers:
        candidates = [name for name in symbols_dict.keys()]
    else:
        candidates = [name for name, meta in symbols_dict.items() if meta.get("kind") not in ("struct", "array", "union")]

    to_add = []
    for name in candidates:
        if (kind, name) in existing_pairs:
            continue
        # If adding MEASUREMENT but CHAR exists, skip; if adding CHAR and MEAS exists, we'll remove MEAS
        has_char = ("CHARACTERISTIC", name) in existing_pairs
        has_meas = ("MEASUREMENT", name) in existing_pairs
        if kind == "MEASUREMENT" and has_char:
            continue
        to_add.append(name)

    # Remove MEASUREMENTs that will be replaced by CHARACTERISTICs
    if kind == "CHARACTERISTIC":
        to_remove_ranges: List[Tuple[int, int]] = []
        parsed_blocks, _ = parse_a2l_blocks(updated_lines)
        targ = set(to_add)
        for b in parsed_blocks:
            if b.kind == "MEASUREMENT" and b.symbol in targ:
                to_remove_ranges.append((b.begin_idx, b.end_idx))
        if to_remove_ranges:
            print(f"Removing {len(to_remove_ranges)} MEASUREMENT block(s) to prefer new CHARACTERISTIC(s).")
            for begin, end in sorted(to_remove_ranges, key=lambda t: t[0], reverse=True):
                del updated_lines[begin:end + 1]
            blocks, _ = parse_a2l_blocks(updated_lines)

    # Build insertion payload with template-following
    insert_lines: List[str] = []
    templates = _select_block_templates(updated_lines)
    tmpl = templates.get(kind)

    for idx, name in enumerate(sorted(to_add)):
        meta = symbols_dict.get(name, {})
        addr_hex = to_upper_hex(meta.get("address", "0x0"))
        if tmpl:
            block_lines = _render_from_template(kind, name, addr_hex, tmpl)
        else:
            block_lines = _render_new_block_minimal(name, kind, addr_hex, meta)
        insert_lines.extend(block_lines)
        if idx != len(to_add) - 1:
            insert_lines.append("\n")

    if not insert_lines:
        print("No new filtered symbols to add; only addresses were updated.")
        updated_lines = _enforce_prefer_characteristic_inplace(updated_lines)
        updated_lines = force_uppercase_known_address_keywords(updated_lines)
        with open(outputfile, "w", encoding="utf-8", errors="ignore") as f:
            f.writelines(updated_lines)
        print(f"Saved updated A2L to: {outputfile}")
        return

    # Find insertion point after the last block of the given kind
    insert_idx = _find_insert_position_after_kind(updated_lines, blocks, kind)

    # Ensure exactly one blank line before the first inserted block (if not at start)
    if insert_idx > 0:
        prev_line = updated_lines[insert_idx - 1]
        if prev_line.strip() != "":
            updated_lines[insert_idx:insert_idx] = ["\n"]
            insert_idx += 1
        else:
            # collapse multiple blank lines to a single one
            k = insert_idx - 1
            while k - 1 >= 0 and updated_lines[k - 1].strip() == "":
                del updated_lines[k - 1]
                insert_idx -= 1
                k -= 1

    # Insert
    updated_lines[insert_idx:insert_idx] = insert_lines

    updated_lines = _enforce_prefer_characteristic_inplace(updated_lines)
    updated_lines = force_uppercase_known_address_keywords(updated_lines)

    with open(outputfile, "w", encoding="utf-8", errors="ignore") as f:
        f.writelines(updated_lines)
    print(f"Appended {len(to_add)} new {kind} block(s) after last {kind} section and saved to: {outputfile}")

def mergea2l(a2l_files: Union[str, List[str]], outputfile: str, elf: Optional[str] = None) -> None:
    """
    Merge multiple A2L files (preserving nested content), prefer CHARACTERISTIC on duplicates,
    append MEASUREMENTs after the last MEASUREMENT in the first A2L, and optionally update addresses.
    """
    if isinstance(a2l_files, str):
        a2l_files = [a2l_files]
    a2l_files = [p for p in a2l_files if str(p).strip()]
    if len(a2l_files) < 1:
        raise ValueError("At least one A2L file must be provided to merge.")

    # Load all files
    files_data: List[Tuple[str, List[str], List[A2LBlock]]] = []
    for path in a2l_files:
        with open(path, "r", encoding="utf-8", errors="ignore") as f:
            lines = f.readlines()
        blocks, _ = parse_a2l_blocks(lines)
        files_data.append((path, lines, blocks))

    # Base
    base_path, base_lines, base_blocks = files_data[0]
    print(f"Using base A2L: {base_path}")
    base_lines = _enforce_prefer_characteristic_inplace(base_lines)
    base_blocks, _ = parse_a2l_blocks(base_lines)

    existing_pairs: Set[Tuple[str, str]] = {(b.kind, b.symbol) for b in base_blocks}
    char_symbols: Set[str] = set()
    for _, _, blocks in files_data:
        for b in blocks:
            if b.kind == "CHARACTERISTIC":
                char_symbols.add(b.symbol)

    added_meas_blocks: List[List[str]] = []
    added_char_blocks: List[List[str]] = []

    # Collect missing blocks from subsequent files
    for path, lines, blocks in files_data[1:]:
        print(f"Scanning A2L file for merge: {path}")
        for b in blocks:
            key = (b.kind, b.symbol)
            if key in existing_pairs:
                continue
            if b.symbol in char_symbols and b.kind == "MEASUREMENT":
                continue
            block_lines = lines[b.begin_idx:b.end_idx + 1]
            if b.kind == "MEASUREMENT":
                added_meas_blocks.append(block_lines)
            else:
                added_char_blocks.append(block_lines)
            existing_pairs.add(key)

    # Insert measurements after last measurement of base
    if added_meas_blocks:
        print(f"Adding {len(added_meas_blocks)} MEASUREMENT block(s) to base A2L.")
        insert_lines_meas: List[str] = []
        for idx, bl in enumerate(added_meas_blocks):
            insert_lines_meas.extend(bl)
            if idx != len(added_meas_blocks) - 1:
                insert_lines_meas.append("\n")

        insert_idx_meas = _find_insert_position_after_kind(base_lines, base_blocks, "MEASUREMENT")
        if insert_idx_meas > 0:
            if base_lines[insert_idx_meas - 1].strip() != "":
                base_lines[insert_idx_meas:insert_idx_meas] = ["\n"]
                insert_idx_meas += 1
            else:
                k = insert_idx_meas - 1
                while k - 1 >= 0 and base_lines[k - 1].strip() == "":
                    del base_lines[k - 1]
                    insert_idx_meas -= 1
                    k -= 1
        base_lines[insert_idx_meas:insert_idx_meas] = insert_lines_meas
        base_blocks, _ = parse_a2l_blocks(base_lines)

    # Insert characteristics
    if added_char_blocks:
        print(f"Adding {len(added_char_blocks)} CHARACTERISTIC block(s) to base A2L.")
        insert_lines_char: List[str] = []
        for idx, bl in enumerate(added_char_blocks):
            insert_lines_char.extend(bl)
            if idx != len(added_char_blocks) - 1:
                insert_lines_char.append("\n")

        insert_idx_char = _find_insert_position_after_kind(base_lines, base_blocks, "CHARACTERISTIC")
        if insert_idx_char > 0:
            if base_lines[insert_idx_char - 1].strip() != "":
                base_lines[insert_idx_char:insert_idx_char] = ["\n"]
                insert_idx_char += 1
            else:
                k = insert_idx_char - 1
                while k - 1 >= 0 and base_lines[k - 1].strip() == "":
                    del base_lines[k - 1]
                    insert_idx_char -= 1
                    k -= 1
        base_lines[insert_idx_char:insert_idx_char] = insert_lines_char

    # Normalize known address keywords
    base_lines = force_uppercase_known_address_keywords(base_lines)

    # Optional address update (also patches nested LINK_MAP/MAP)
    if elf:
        print(f"Updating addresses in merged A2L using ELF: {elf}")
        merged_blocks, filters = parse_a2l_blocks(base_lines)
        if filters:
            try:
                symbols_dict, missing_filters = build_symbols_dict(elf, filters)
                addr_map = {name: to_upper_hex(meta["address"]) for name, meta in symbols_dict.items()}
                base_lines, warnings = update_a2l_lines(base_lines, merged_blocks, addr_map)
                for w in warnings:
                    print("Warning:", w)
                if missing_filters:
                    print("These A2L symbols were not found in ELF/DWARF:")
                    for s in sorted(missing_filters):
                        print(f" - {s}")
            except Exception as e:
                print(f"Warning: Failed to update addresses from ELF: {e}")
        else:
            print("No symbols found to update in merged A2L.")

    with open(outputfile, "w", encoding="utf-8", errors="ignore") as f:
        f.writelines(base_lines)

    print(f"Merged A2L saved to: {outputfile}")

# ----------------------------
# CLI
# ----------------------------

def _main(argv: List[str]) -> int:
    if len(argv) < 2:
        print(f"Usage:\n"
              f"  {argv[0]} update <olda2l> <elf> <newa2l>\n"
              f"  {argv[0]} add <olda2l> <elf> <variablename|list> <characteristic|measurement> <outputfile> [--leaves-only|--include-containers]\n"
              f"  {argv[0]} merge <outputfile> <a2l1> [<a2l2> ...] [--elf <elf>]\n\n"
              f"Notes:\n"
              f"- Updates also patch nested LINK_MAP/MAP lines (symbol + address) inside blocks.\n"
              f"- 'add' clones a template block from the file (preserves IF_DATA, LINK_MAP, etc.).\n"
              f"- Preference: if a symbol exists as both MEASUREMENT and CHARACTERISTIC, CHARACTERISTIC is kept.")
        return 1

    cmd = argv[1].lower()
    if cmd == "update":
        if len(argv) < 5:
            print(f"Usage: {argv[0]} update <olda2l> <elf> <newa2l>")
            return 1
        _, _, olda2l, elf, newa2l = argv[:5]
        Updatea2l(olda2l, elf, newa2l)
        return 0

    if cmd == "add":
        if len(argv) < 7:
            print(f"Usage: {argv[0]} add <olda2l> <elf> <variablename|list> <characteristic|measurement> <outputfile> [--leaves-only|--include-containers]")
            return 1
        _, _, olda2l, elf, variablename_arg, vartype, outputfile = argv[:7]
        flags = set(a.lower() for a in argv[7:])
        include_containers = DEFAULT_INCLUDE_CONTAINERS
        if "--leaves-only" in flags:
            include_containers = False
        if "--include-containers" in flags:
            include_containers = True
        variablename_list = _normalize_variablename_input(variablename_arg)
        addvariable(olda2l, elf, variablename_list, vartype, outputfile, include_containers=include_containers)
        return 0

    if cmd == "merge":
        if len(argv) < 5:
            print(f"Usage: {argv[0]} merge <outputfile> <a2l1> [<a2l2> ...] [--elf <elf>]")
            return 1
        args = argv[2:]
        elf_path: Optional[str] = None
        if "--elf" in args:
            idx = args.index("--elf")
            if idx + 1 >= len(args):
                print(f"Usage: {argv[0]} merge <outputfile> <a2l1> [<a2l2> ...] [--elf <elf>]")
                return 1
            elf_path = args[idx + 1]
            args = args[:idx] + args[idx + 2:]
        if len(args) < 2:
            print(f"Usage: {argv[0]} merge <outputfile> <a2l1> [<a2l2> ...] [--elf <elf>]")
            return 1
        outputfile = args[0]
        a2l_files = args[1:]
        mergea2l(a2l_files, outputfile, elf=elf_path)
        return 0

    print(f"Unknown command: {cmd}")
    return 1

if __name__ == "__main__":
    sys.exit(_main(sys.argv))
